{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dir = '../data/raw/'\n",
    "filename = 'BMMS_overview.xlsx'\n",
    "df_bridges = pd.read_excel(dir + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import roads_transposed.csv\n",
    "dir = '../data/processed/'\n",
    "filename = '_roads_cleaned.csv' # replace this with the interpolated data\n",
    "df_roads = pd.read_csv(dir + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Clean bridge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap 'lat' and 'lon' if both are out of bounds\n",
    "\n",
    "# Define latitude and longitude boundaries\n",
    "LAT_MIN, LAT_MAX = 20, 28\n",
    "LON_MIN, LON_MAX = 88, 93\n",
    "\n",
    "def swap_coordinates(row):\n",
    "    if not (LAT_MIN <= row['lat'] <= LAT_MAX) and not (LON_MIN <= row['lon'] <= LON_MAX):\n",
    "        row['lat'], row['lon'] = row['lon'], row['lat']  # Swap values\n",
    "    return row\n",
    "\n",
    "def clean_bridge_data(df_bridges):\n",
    "    # make a copy of the original data\n",
    "    bridge = df_bridges.copy()\n",
    "\n",
    "    # delete the rows with missing values in column 'lat' or 'lon'\n",
    "    bridge_new = bridge.dropna(subset=['lat', 'lon'])\n",
    "\n",
    "    # delete the rows with 0 in column 'lat' or 'lon'\n",
    "    bridge_new = bridge_new[(bridge_new['lat'] != 0) & (bridge_new['lon'] != 0)]\n",
    "\n",
    "    # create a new column 'road_LRPName' by combining 'road' and 'LRPName'\n",
    "    bridge_new = bridge_new.copy()\n",
    "    bridge_new['road_LRPName'] = bridge_new['road'] + '_' + bridge_new['LRPName']\n",
    "\n",
    "    # add a column 'null_num' with the calculattion of the number of null values for the each row\n",
    "    bridge_new['null_num'] = bridge_new.isnull().sum(axis=1)\n",
    "\n",
    "    # delete the rows with duplicated 'road_LRPName' and keep the row with the minimum number of null values\n",
    "    bridge_new = bridge_new.loc[bridge_new.groupby('road_LRPName')['null_num'].idxmin()]\n",
    "\n",
    "    # find the duplicated 'road_LRPName'\n",
    "    bridge_new[bridge_new.duplicated(subset='road_LRPName', keep=False)]\n",
    "\n",
    "    # sort the data by 'road'\n",
    "    #bridge_new = bridge_new.sort_values(by=['road', 'LRPName'])\n",
    "\n",
    "    # Find the rows with 'lat' and 'lon' out of bounds\n",
    "    bridge_new[(bridge_new['lat'] < LAT_MIN) |\n",
    "               (bridge_new['lat'] > LAT_MAX) |\n",
    "               (bridge_new['lon'] < LON_MIN) | \n",
    "               (bridge_new['lon'] > LON_MAX)]\n",
    "    \n",
    "    bridge_new = bridge_new.apply(swap_coordinates, axis=1)\n",
    "\n",
    "    # Find the rows with 'lat' and 'lon' out of bounds\n",
    "    bridge_new[(bridge_new['lat'] < LAT_MIN) | \n",
    "               (bridge_new['lat'] > LAT_MAX) | \n",
    "               (bridge_new['lon'] < LON_MIN) | \n",
    "               (bridge_new['lon'] > LON_MAX)]\n",
    "    \n",
    "    return bridge_new\n",
    "\n",
    "cleaned_bridges = clean_bridge_data(df_bridges)\n",
    "#cleaned_bridges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a .xlsx file\n",
    "dir = '../data/processed/'\n",
    "filename = 'BMMS_overview_cleaned_prelim.xlsx'\n",
    "cleaned_bridges.to_excel(dir + filename, index=False, sheet_name='BMMS_overview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Remove bridges without roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Move\\AppData\\Local\\Temp\\ipykernel_23272\\4205491286.py:78: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_modified = pd.concat(modified_rows)\n",
      "C:\\Users\\Move\\AppData\\Local\\Temp\\ipykernel_23272\\4205491286.py:106: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  removed_rows_df = pd.concat([removed_rows_df, removed_rows])\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the LRPE for each road\n",
    "lrpe_dict = {}\n",
    "\n",
    "# Create a dictionary to store the one LRP before LRPE for each road\n",
    "lrp_before_lrpe = {}\n",
    "\n",
    "# Iterate over each unique road\n",
    "for road in df_roads['road'].unique():\n",
    "    # Get the rows for the current road\n",
    "    road_rows = df_roads[df_roads['road'] == road]\n",
    "    \n",
    "    # Find the index of LRPE\n",
    "    if 'LRPE' in road_rows['lrp'].values:\n",
    "        lrpe_indices = road_rows[road_rows['lrp'] == 'LRPE'].index\n",
    "        if len(lrpe_indices) > 0:\n",
    "            lrpe_index = lrpe_indices[0]\n",
    "            lrpe_dict[road] = road_rows.loc[lrpe_index, 'lrp']\n",
    "            if lrpe_index > 0 and lrpe_index - 1 < len(road_rows):\n",
    "                lrp_before_lrpe[road] = road_rows.iloc[lrpe_index - 1]['lrp']\n",
    "            else:\n",
    "                lrp_before_lrpe[road] = road_rows.iloc[-2]['lrp']\n",
    "        else:\n",
    "            lrp_before_lrpe[road] = road_rows.iloc[-2]['lrp']\n",
    "    else:\n",
    "        # Remember the last LRP if there is no LRPE\n",
    "        lrp_before_lrpe[road] = road_rows.iloc[-1]['lrp']\n",
    "        lrpe_dict[road] = None  # Add a placeholder for LRPE\n",
    "\n",
    "# Combine the dictionaries into a dataframe\n",
    "df_lrpe_road = pd.DataFrame({\n",
    "    'road': lrpe_dict.keys(),\n",
    "    'LRP_before_E': lrp_before_lrpe.values(),\n",
    "    'LRPE': lrpe_dict.values()\n",
    "})\n",
    "#df_lrpe_road.head()\n",
    "\n",
    "# Sort the dataframe by road and LRP, but keep 'LRPS' at the start\n",
    "def custom_sort(df):\n",
    "    df['lrp_order'] = df['LRPName'].apply(lambda x: 0 if 'LRPS' in x else 1)\n",
    "    df = df.sort_values(by=['road', 'lrp_order', 'LRPName'])\n",
    "    df = df.drop(columns=['lrp_order'])\n",
    "    return df\n",
    "\n",
    "cleaned_bridges_sorted = custom_sort(cleaned_bridges)\n",
    "\n",
    "import re\n",
    "\n",
    "# Function to extract numeric part from LRPName\n",
    "def extract_numeric(lrp_name):\n",
    "    match = re.search(r'\\d+', lrp_name)\n",
    "    return int(match.group()) if match else float('inf')\n",
    "\n",
    "# Function to remove rows with lrp after 'LRP_before_E' for each unique road\n",
    "def remove_rows_after_lrp_before_e(df, df_lrpe):\n",
    "    modified_rows = []\n",
    "    for _, row in df_lrpe.iterrows():\n",
    "        road = row['road']\n",
    "        lrp_before_e = row['LRP_before_E']\n",
    "        \n",
    "        # Get the rows for the current road\n",
    "        road_rows = df[df['road'] == road].copy()\n",
    "        \n",
    "        # Extract numeric part from LRPName and sort\n",
    "        road_rows['lrp_numeric'] = road_rows['LRPName'].apply(extract_numeric)\n",
    "        road_rows = road_rows.sort_values(by='lrp_numeric')\n",
    "        \n",
    "        # Get the index of the row with 'LRP_before_E'\n",
    "        lrp_before_e_indices = road_rows[road_rows['LRPName'] == lrp_before_e].index\n",
    "        \n",
    "        if not lrp_before_e_indices.empty:\n",
    "            lrp_before_e_index = lrp_before_e_indices[-1]  # Get the last occurrence\n",
    "            # Drop rows after 'LRP_before_E'\n",
    "            road_rows = road_rows[road_rows['lrp_numeric'] <= road_rows.loc[lrp_before_e_index, 'lrp_numeric']]\n",
    "        \n",
    "        modified_rows.append(road_rows)\n",
    "    \n",
    "    # Concatenate all modified rows\n",
    "    df_modified = pd.concat(modified_rows)\n",
    "    \n",
    "    return df_modified.drop(columns=['lrp_numeric'])\n",
    "\n",
    "# Apply the function to df_roads_bridges_combined_sorted\n",
    "df_bridges_no_lrp_after_e = remove_rows_after_lrp_before_e(cleaned_bridges_sorted, df_lrpe_road)\n",
    "#df_bridges_no_lrp_after_e\n",
    "\n",
    "# Remove columns 'road_LRPName' and 'null_num'\n",
    "df_final_bridges = df_bridges_no_lrp_after_e.drop(columns=['road_LRPName', 'null_num'])\n",
    "\n",
    "# reset the index\n",
    "df_final_bridges = df_final_bridges.reset_index(drop=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create an empty dataframe to store the removed rows\n",
    "removed_rows_df = pd.DataFrame(columns=cleaned_bridges.columns)\n",
    "\n",
    "# Compare cleaned_bridges with df_final_bridges; save lrps that are removed\n",
    "for road in df_final_bridges['road'].unique():\n",
    "    cleaned_lrps = cleaned_bridges[cleaned_bridges['road'] == road]['LRPName'].values\n",
    "    final_lrps = df_final_bridges[df_final_bridges['road'] == road]['LRPName'].values\n",
    "    \n",
    "    removed_lrps = np.setdiff1d(cleaned_lrps, final_lrps)\n",
    "    \n",
    "    if len(removed_lrps) > 0:\n",
    "        removed_rows = cleaned_bridges[(cleaned_bridges['road'] == road) & (cleaned_bridges['LRPName'].isin(removed_lrps))]\n",
    "        removed_rows_df = pd.concat([removed_rows_df, removed_rows])\n",
    "\n",
    "removed_rows_df.reset_index(drop=True, inplace=True)\n",
    "#removed_rows_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new excel file\n",
    "dir = '../data/processed/'\n",
    "filename = 'BMMS_overview_cleaned_bridges_after_LPRE_removed.xlsx'\n",
    "df_final_bridges.to_excel(dir + filename, index=False, sheet_name='BMMS_overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new excel file\n",
    "dir = '../data/processed/'\n",
    "filename = 'BMMS_overview_removed_lrps.xlsx'\n",
    "removed_rows_df.to_excel(dir + filename, index=False, sheet_name='BMMS_overview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Adjust Bridge Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def adjust_bridge_coordinates_simple(df_bridges, df_roads):\n",
    "    adjusted_bridges = df_bridges.copy()\n",
    "    \n",
    "    for road in df_bridges['road'].unique():\n",
    "        road_rows = df_roads[df_roads['road'] == road]\n",
    "        road_points = list(zip(road_rows['lon'], road_rows['lat']))\n",
    "        if len(road_points) == 0:\n",
    "            continue\n",
    "        tree = cKDTree(road_points)\n",
    "        \n",
    "        for idx, bridge_row in df_bridges[df_bridges['road'] == road].iterrows():\n",
    "            bridge_point = (bridge_row['lon'], bridge_row['lat'])\n",
    "            dist, idx_closest = tree.query(bridge_point)\n",
    "            closest_point = road_points[idx_closest]\n",
    "            \n",
    "            adjusted_bridges.at[idx, 'lat'] = closest_point[1]\n",
    "            adjusted_bridges.at[idx, 'lon'] = closest_point[0]\n",
    "    \n",
    "    return adjusted_bridges\n",
    "\n",
    "df_final_bridges_adjusted = adjust_bridge_coordinates_simple(df_final_bridges, df_roads)\n",
    "#df_final_bridges_adjusted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save excel file: Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a .xlsx file\n",
    "dir = '../data/processed/'\n",
    "filename = 'BMMS_overview.xlsx'\n",
    "df_final_bridges_adjusted.to_excel(dir + filename, index=False, sheet_name='BMMS_overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gds24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
